{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Definitions\n",
    "\n",
    "This module has the following objectives:\n",
    "- Creating a graph from Unstructured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHKg4DVZiQ98"
   },
   "outputs": [],
   "source": [
    "# !pip install graphdatascience neo4j dotenv pydantic openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import our usual suspects (and some more...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import Query, GraphDatabase, RoutingControl, Result\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynPe6RLRWSKd"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa61u1jfyk3t"
   },
   "source": [
    "Load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file = '../ws.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHR_0lmElZ-R"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(env_file):\n",
    "    load_dotenv(env_file, override=True)\n",
    "\n",
    "    # Neo4j\n",
    "    HOST = os.getenv('NEO4J_URI')\n",
    "    USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "    PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "    DATABASE = os.getenv('NEO4J_DATABASE')\n",
    "\n",
    "    # AI\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    os.environ['OPENAI_API_KEY']=OPENAI_API_KEY\n",
    "    LLM = os.getenv('LLM')\n",
    "    EMBEDDINGS_MODEL = os.getenv('EMBEDDINGS_MODEL')\n",
    "else:\n",
    "    print(f\"File {env_file} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to neo4j db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "    HOST,\n",
    "    auth=(USERNAME, PASSWORD)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5w4eCb7xZZ-S"
   },
   "outputs": [],
   "source": [
    "driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (n) RETURN COUNT(n) as Count\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some unstrucutured data from some of our documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (c:Chunk)-[:PART_OF]->(d:Document) RETURN c.chunk_eng as text, c.id as chunk_id, d.file_name as document\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Domain Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pydantic Models](https://docs.pydantic.dev/latest/api/base_model/) are simply classes which inherit from BaseModel and define fields as annotated attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Definition(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a term with its definition and description.\n",
    "    \"\"\"\n",
    "    term: str = Field(..., description=\"The description or explanation of the term\")\n",
    "    description: str = Field(..., description=\"The description or explanation of the term\")\n",
    "    chunk_id: int = Field(..., description=\"The id of the chunk from which the term was derived from.\")\n",
    "\n",
    "class DefinitionList(BaseModel):\n",
    "    definitions:List[Definition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "    You are an expert in identifying definitions and terms in a piece of text. \n",
    "    Identify defnitions/terms that are explicitly explained in the text. Please extract the following details: \n",
    "    - Term: The description or explanation of the term \n",
    "    - Description: The description or explanation of the term\n",
    "    - chunk_id: The id of the chunk from which the term was derived from. \n",
    "\n",
    "    Be concise, take the following points in consideration:\n",
    "    - Don't come up with anything yourself. \n",
    "    - Focus on terms that are explained in the text. Focus on abbreviations and specific context depended terms. \n",
    "    - Only map explicit definitions and terms that are explained in the text.\n",
    "    - Don't state obvious terms but focus on specific ones here. \n",
    "    - Don't translate things. Only store them in the origal language.\n",
    "    - Skip chapters or sections headers which are very generic. \n",
    "\n",
    "    Present the extracted information in a clear, structured format. Be concise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(document, chunk_id, model=LLM, temperature=0):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": document},\n",
    "            {\"role\": \"user\", \"content\": \"chunk_id: \" + str(chunk_id)},\n",
    "        ],\n",
    "        response_format=DefinitionList,\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _, row in chunk_df.iterrows(): \n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [extract(row.text, row.chunk_id) for _, row in chunk_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {'definitions': [entry for d in rows for entry in d['definitions']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data = DefinitionList.model_validate({'definitions': rows['definitions']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, details_list in structured_data.model_dump().items():\n",
    "    print(f\"{k}\")\n",
    "    for details in details_list:\n",
    "        for key, value in details.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OMlYdxHWZLx"
   },
   "source": [
    "## Graph creation\n",
    "Now that data is structured and validated, we can save it to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Definition Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, summary, keys = driver.execute_query(\n",
    "    \"\"\"\n",
    "        UNWIND $rows AS row\n",
    "        MERGE (d:Definition{term:LOWER(row.term)})\n",
    "        SET d.description = row.description\n",
    "        SET d.original_chunk_id = row.chunk_id\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE,\n",
    "    rows = rows['definitions']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create relationships to Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, summary, keys = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (d:Definition)\n",
    "    MATCH (c:Chunk)\n",
    "    WHERE toLower(c.chunk_eng) CONTAINS toLower(d.term)\n",
    "    MERGE (c)-[:MENTIONS]->(d)\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.WRITE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embeddings on definitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model = EMBEDDINGS_MODEL,\n",
    "    openai_api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = driver.execute_query(\n",
    "    \"\"\"\n",
    "    MATCH (def:Definition)\n",
    "    RETURN def.term AS term, def.description AS description\n",
    "    \"\"\",\n",
    "    database_=DATABASE,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding'] = df['term'].apply(lambda x: embeddings_model.embed_query(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    driver.execute_query(\n",
    "        \"\"\"\n",
    "        MATCH (def:Definition {term: $term})\n",
    "        SET def.embedding = $embedding\n",
    "        WITH def\n",
    "        CALL db.create.setNodeVectorProperty(def, \"embedding\", def.embedding)\n",
    "        \"\"\",\n",
    "        database_=DATABASE,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        result_transformer_= lambda r: r.to_df(),\n",
    "        term=row['term'],\n",
    "        embedding=row['embedding']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
